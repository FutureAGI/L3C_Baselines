---
run_name: Test

log_config:
  use_tensorboard: True
  tensorboard_log: ./runs/
  training_log: ./runs/train.log
  evaluation_log: ./runs/eval.log

model_config:
  context_warmup: 1536
  max_position_loss_weighting: 48000
  action_dim: 5
  policy_loss_type: CrossEntropy
  rsa_type: sar

  state_encode:
      input_type: Discrete
      input_size: 128
      hidden_size: 512
      dropout: 0.0

  action_encode:
      input_type: Discrete
      input_size: 6
      hidden_size: 512
      dropout: 0.0

  prompt_encode:
      input_type: Continuous
      input_size: 1
      hidden_size: 512
      dropout: 0.0

  reward_encode:
      input_type: Continuous
      input_size: 1
      hidden_size: 512
      dropout: 0.0

  state_decode:
      output_type: Discrete
      input_size: 512
      hidden_size:
          - 512
          - 128
      layer_norm: True
      residual_connect: True
      dropout: 0.0

  action_decode:
      output_type: Discrete
      input_size: 512
      hidden_size:
          - 512
          - 6
      layer_norm: True
      residual_connect: True
      dropout: 0.0

  reward_decode:
      output_type: Continuous
      input_size: 512
      hidden_size:
          - 512
          - 1
      layer_norm: True
      residual_connect: True
      dropout: 0.0

  causal_block_bak_1:
      model_type: TRANSFORMER
      num_layers: 6
      hidden_size: 512
      nhead: 8
      inner_hidden_size: 512
      dropout: 0.10
      context_window: -1
      checkpoints_density: -1
      position_encoding_size: 12000
      use_layer_norm: True
      use_blockrecurrence: True
      memory_length: 3000
      memory_type: KV

  causal_block_bak_2:
      model_type: GSA # GLA
      num_layers: 12
      hidden_size: 512
      inner_hidden_size: 1024
      dropout: 0.10
      nhead: 16
      memory_length: 128
      position_encoding_size: 12000
      use_layer_norm: True
      use_blockrecurrence: True
      checkpoints_density: -1
      memory_type: MEM

  causal_block_bak_3:
      model_type: RWKV6
      num_layers: 12
      hidden_size: 512
      inner_hidden_size: 1024
      dropout: 0.10
      nhead: 16
      expand_k: 0.5
      expand_v: 1
      hidden_ratio: 3.5
      position_encoding_size: 12000
      use_layer_norm: True
      use_blockrecurrence: True
      checkpoints_density: -1
      memory_length: 0
      memory_type: MEM

  causal_block_bak_4:  # Mamba has unsolved issues in cache, temporarily avoid using it
      model_type: Mamba
      num_layers: 12
      hidden_size: 512
      inner_hidden_size: 1024
      expand: 2
      d_conv: 4
      d_state: 16
      dropout: 0.10
      position_encoding_size: 12000
      use_layer_norm: True
      use_blockrecurrence: True
      checkpoints_density: -1
      memory_length: 0

train_config:
    max_epochs: 15
    batch_size: 8

    seq_len: 16000
    seg_len: 2000

    lr: 5.0e-4
    lr_decay_interval: 2000
    lr_start_step: 0

    data_path: "[PATH]"
    save_model_path: "./checkpoints/"
    load_model_path: None
    master_port: "12400"
    max_save_iterations: 500
    evaluation_interval: 1

    lossweight_policymodel: 0.0
    lossweight_worldmodel_states: 1.0
    lossweight_worldmodel_rewards: 0.0
    lossweight_entropy: 0.0 
    lossweight_l2: 1.0e-10

    use_amp: False
    use_scaler: False

    load_model_parameter_blacklist:
        - None

test_config:
    batch_size: 16
    data_path: "[PATH]"
    master_port: "12201"
    load_model_path: None
    seq_len: 16000
    seg_len: 4000
    downsample_size: 10
    output: "./plot/"

demo_config:
    master_port: "12211"
    seg_len: 2000
    task_num: 20000
    time_step: 2048

    model_config:
        load_model_path: "[PATH]"
        autoregressive_steps:
            - 0
            - 100
            - 1000
            - 2000
        autoregressive_length: 10
        policy:
            T_ini: 1.0
            T_dec: 0.005
            T_min: 0.01
        load_model_parameter_blacklist:
            - "attn_mask"
    maze_config:
        scale: 15
        density: 0.36
        n_landmarks: 10
    rule_config:
        mem_kr: 1.0
    run_model: 0
    run_rule: 1
    run_random: 0
    task_file: "[PATH]"
    write_video: 0
    output: "[PATH]"
